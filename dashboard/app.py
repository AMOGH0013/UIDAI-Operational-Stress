import pathlib

import geopandas as gpd
import pandas as pd
import pydeck as pdk
import streamlit as st


@st.cache_data(show_spinner=False)
def load_data() -> pd.DataFrame:
    """
    Load the final risk scores CSV generated by the notebooks.

    Expects: data/processed/final_risk_scores.csv at project root.
    """
    project_root = pathlib.Path(__file__).resolve().parents[1]
    data_path = project_root / "data" / "processed" / "final_risk_scores.csv"

    if not data_path.exists():
        st.error(
            f"Processed data not found at {data_path}. "
            "Run the 'ADVANCED LAYER' notebook to generate final_risk_scores.csv."
        )
        return pd.DataFrame()

    df = pd.read_csv(data_path)
    return df


@st.cache_data(show_spinner=False)
def load_geodata(df_risk: pd.DataFrame) -> gpd.GeoDataFrame:
    """
    Load the India district shapefile and merge with the risk dataframe.

    - Reads: data/shapefile/2011_Dist.shp
    - Normalises district names on both sides for a robust merge.
    """
    if df_risk.empty:
        return gpd.GeoDataFrame()

    project_root = pathlib.Path(__file__).resolve().parents[1]
    shp_path = project_root / "data" / "shapefile" / "2011_Dist.shp"

    if not shp_path.exists():
        st.error(
            f"Shapefile not found at {shp_path}. "
            "Ensure 2011_Dist.shp and its companion files are present in data/shapefile/."
        )
        return gpd.GeoDataFrame()

    gdf = gpd.read_file(shp_path)

    # Try to infer district name column in shapefile
    district_col_candidates = ["district", "DISTRICT", "DIST_NAME", "DISTRICT_N"]
    shp_district_col = None
    for col in district_col_candidates:
        if col in gdf.columns:
            shp_district_col = col
            break

    if shp_district_col is None:
        st.error(
            "Could not find a district name column in the shapefile. "
            "Expected one of: 'district', 'DISTRICT', 'DIST_NAME', 'DISTRICT_N'."
        )
        return gpd.GeoDataFrame()

    if "district" not in df_risk.columns:
        st.error(
            "Risk data does not contain a 'district' column required for spatial merge."
        )
        return gpd.GeoDataFrame()

    # Normalise both sides for a robust join
    gdf = gdf.copy()
    df_risk = df_risk.copy()

    gdf["district_key"] = gdf[shp_district_col].astype(str).str.strip().str.upper()
    df_risk["district_key"] = df_risk["district"].astype(str).str.strip().str.upper()

    merged = gdf.merge(df_risk, on="district_key", how="left")

    # Ensure WGS84 for web mapping
    if merged.crs is not None and merged.crs.to_epsg() != 4326:
        merged = merged.to_crs(epsg=4326)

    return merged


def apply_age_filter(df: pd.DataFrame, selected_groups: list[str]) -> pd.DataFrame:
    """
    Filter dataframe based on selected age groups, if age information is available.

    Supports two possible schemas:
    1. A categorical column named 'age_group' containing values like
       'Infants', 'Adults', 'Seniors'.
    2. Wide-format numeric columns such as 'infants', 'adults', 'seniors'
       (in which case we keep all rows but later metrics can selectively
       aggregate the chosen columns).

    If neither is present, the function returns df unchanged.
    """
    if df.empty:
        return df

    # Case 1: tidy age-group column
    if "age_group" in df.columns:
        return df[df["age_group"].isin(selected_groups)]

    # Case 2: wide age columns â€” no row filtering; handled in metric calcs
    return df


def compute_metrics(df: pd.DataFrame) -> tuple[float | None, float | None, int | None]:
    """
    Compute:
    - Total Aadhaar Records
    - Average National Risk Index
    - Districts Flagged for High Stress

    Falls back gracefully depending on which columns are available.
    """
    if df.empty:
        return None, None, None

    # ----- Total Aadhaar Records -----
    total_cols = [
        col
        for col in df.columns
        if col.lower() in {"enrolment_total", "demographic_total", "biometric_total"}
    ]

    total_records = None
    if total_cols:
        total_records = float(df[total_cols].sum().sum())

    # ----- Average National Risk Index -----
    risk_series = None
    # Preferred: a dedicated escalation / risk index column
    for candidate in ["escalation_risk", "risk_index", "operational_risk_index"]:
        if candidate in df.columns:
            risk_series = df[candidate]
            break

    # Fallback: use ratio-based proxy if available
    if risk_series is None and {
        "demo_to_enrol_ratio",
        "bio_to_enrol_ratio",
    }.issubset(df.columns):
        risk_series = (df["demo_to_enrol_ratio"] + df["bio_to_enrol_ratio"]) / 2.0

    avg_risk = float(risk_series.mean()) if risk_series is not None else None

    # ----- Districts Flagged for High Stress -----
    high_stress_count = None

    if "stress_type" in df.columns:
        # Anything not explicitly low stress is treated as high stress
        high_mask = df["stress_type"].ne("Low Stress")
        high_stress_count = int(high_mask.sum())
    elif risk_series is not None:
        # Flag districts above median risk as "high stress"
        threshold = risk_series.median()
        high_stress_count = int((risk_series > threshold).sum())

    return total_records, avg_risk, high_stress_count


def get_risk_series(df: pd.DataFrame) -> pd.Series | None:
    """
    Helper to retrieve the operational escalation risk series used
    for colouring the map.
    """
    if df.empty:
        return None

    for candidate in ["escalation_risk", "risk_index", "operational_risk_index"]:
        if candidate in df.columns:
            return df[candidate]

    if {"demo_to_enrol_ratio", "bio_to_enrol_ratio"}.issubset(df.columns):
        return (df["demo_to_enrol_ratio"] + df["bio_to_enrol_ratio"]) / 2.0

    return None


def main() -> None:
    st.set_page_config(
        page_title="UIDAI Operational Stress Dashboard",
        layout="wide",
    )

    st.title("UIDAI Operational Stress & Predictive Analytics")
    st.caption("Operational Escalation Risk Index & 30-day Predictive Signals (Prototype)")

    # ----- Sidebar: Filters -----
    st.sidebar.header("Filters")

    age_options = ["Infants", "Adults", "Seniors"]
    selected_age_groups = st.sidebar.multiselect(
        "Age Groups",
        options=age_options,
        default=age_options,
        help="Filter the view by age-group segments, where available.",
    )

    # ----- Load & filter data -----
    df = load_data()

    if df.empty:
        st.stop()

    filtered_df = apply_age_filter(df, selected_age_groups)

    # ----- Top metrics row -----
    total_records, avg_risk, high_stress_count = compute_metrics(filtered_df)

    col1, col2, col3 = st.columns(3)

    with col1:
        if total_records is not None:
            st.metric(
                label="Total Aadhaar Records",
                value=f"{int(total_records):,}",
            )
        else:
            st.metric(label="Total Aadhaar Records", value="N/A")

    with col2:
        if avg_risk is not None:
            st.metric(
                label="Average National Risk Index",
                value=f"{avg_risk:0.3f}",
            )
        else:
            st.metric(label="Average National Risk Index", value="N/A")

    with col3:
        if high_stress_count is not None:
            st.metric(
                label="Districts Flagged for High Stress",
                value=f"{high_stress_count:,}",
            )
        else:
            st.metric(label="Districts Flagged for High Stress", value="N/A")

    # ----- Main table / detail view -----
    st.subheader("District-Level Operational View")
    st.dataframe(filtered_df, use_container_width=True, hide_index=True)

    if "stress_type" in filtered_df.columns:
        st.caption("Tip: Use the sidebar filters and sort by stress type or ratios to explore hotspots.")

    # ----- Geographic Choropleth Map -----
    st.subheader("Geographic Escalation Risk Map")

    gdf_merged = load_geodata(filtered_df)

    if gdf_merged.empty or gdf_merged.geometry.isna().all():
        st.info(
            "Map cannot be rendered because spatial data or geometries are missing. "
            "Check that the shapefile and district names align with the risk data."
        )
        return

    risk_series = get_risk_series(gdf_merged)

    if risk_series is None:
        st.info(
            "No explicit Operational Escalation Risk Index found. "
            "Add a risk column (e.g., 'escalation_risk') in the processed data "
            "to enable risk-based colouring on the map."
        )
        return

    # Normalise risk to [0, 1] for colour scaling
    risk_min = float(risk_series.min())
    risk_max = float(risk_series.max())
    denom = risk_max - risk_min if risk_max != risk_min else 1.0
    gdf_merged = gdf_merged.copy()
    gdf_merged["_risk_norm"] = (risk_series - risk_min) / denom

    # Red for high, green for low (with a small alpha)
    def risk_to_color(norm: float) -> list[int]:
        r = int(255 * norm)
        g = int(255 * (1.0 - norm))
        return [r, g, 0, 160]

    gdf_merged["fill_color"] = gdf_merged["_risk_norm"].fillna(0.0).apply(risk_to_color)

    # Convert to a GeoJSON-like mapping for pydeck
    geojson_data = gdf_merged.__geo_interface__

    # Compute a reasonable initial view over India
    minx, miny, maxx, maxy = gdf_merged.total_bounds
    center_lon = (minx + maxx) / 2.0
    center_lat = (miny + maxy) / 2.0

    geojson_layer = pdk.Layer(
        "GeoJsonLayer",
        data=geojson_data,
        pickable=True,
        stroked=True,
        filled=True,
        get_fill_color="properties.fill_color",
        get_line_color=[80, 80, 80, 180],
        line_width_min_pixels=0.5,
    )

    view_state = pdk.ViewState(
        longitude=center_lon,
        latitude=center_lat,
        zoom=3.5,
        min_zoom=3,
        max_zoom=10,
        pitch=0,
    )

    deck = pdk.Deck(
        layers=[geojson_layer],
        initial_view_state=view_state,
        tooltip={
            "html": "<b>District:</b> {district}<br/>"
            "<b>Risk Index:</b> {escalation_risk}",
            "style": {"backgroundColor": "white", "color": "black"},
        },
    )

    st.pydeck_chart(deck)


if __name__ == "__main__":
    main()

